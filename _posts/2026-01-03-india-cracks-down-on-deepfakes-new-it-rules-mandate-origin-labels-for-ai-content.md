---
layout: post
title: "India Cracks Down on Deepfakes: New IT Rules Mandate 'Origin Labels' for AI Content"
description: >-
  The Ministry of Electronics and IT (MeitY) has rolled out the IT Amendment Rules 2026,
  forcing every AI-generated image, video, or audio clip to display a clear origin label
  so people instantly know it was machine-made.
author: ananya-singh
categories: [AI, Cybersecurity]
image: /assets/images/posts/cert-advisory.svg
image_alt: "Illustration showing origin label over AI-created video frame"
lang: en
date: 2026-01-03
excerpt: >-
  India's new IT Amendment Rules 2026 add watermark mandates, 36-hour takedown windows,
  and stricter liabilities for platforms hosting deepfake content.
news_keywords: ["India deepfake laws 2026", "AI content labelling rules", "IT Amendment Rules", "deepfake takedown timeline", "origin watermark", "Ashwini Vaishnaw", "social media regulation"]
tags: [AI, Cybersecurity]
key_takeaways:
  - MeitY now requires visible origin labels covering at least 10% of AI-generated media.
  - Platforms must delete flagged deepfakes within 36 hours or risk losing safe-harbor protections.
  - CERT-In will launch a watermark verification API to help newsrooms validate suspicious files.
last_modified_at: 2026-01-03 10:05:00 +05:30
---

## Origin Labels Become Mandatory Immediately

The Government of India has notified a new chapter of the Information Technology (Intermediary
Guidelines and Digital Media Ethics Code) Rules, 2021, targeting the sharp rise in deepfake
incidents. Branded informally as the "IT Amendment Rules 2026", the policy requires that any
AI-generated photo, video, or audio clip carry a persistent origin label or watermark that covers at
least 10% of the visible frame.

Union IT Minister Ashwini Vaishnaw told reporters that the watermark specification will be aligned
with Bureau of Indian Standards (BIS) guidelines so platforms, creators, and broadcasters adopt a
uniform cue. "People should not have to guess whether a clip is synthetic. The label must be as
obvious as the content itself," he said, adding that non-compliance can trigger penal action under
the IT Act.

## 36-Hour Removal Clock For Platforms

Besides labeling, the amendment shortens the turnaround time for takedowns. Social networks, chat
apps, and short-video platforms now have 36 hours to remove or disable any deepfake flagged by a
user, court, or government notice. Missing the deadline could strip intermediaries of "safe harbor"
protection under Section 79, exposing them to civil or criminal liability for the hosted content.

Cyberlaw expert Pavan Duggal called the timeline demanding but necessary. "Election integrity and
financial scams are on the line. Platforms already have war rooms for terrorism and CSAM takedowns,
so deepfake workflows must receive the same priority," he said. Several companies are reportedly
reconfiguring trust-and-safety dashboards to highlight flagged synthetic media faster.

## Verification API For Newsrooms

To help fact-checkers, MeitY's Indian Computer Emergency Response Team (CERT-In) is building a
watermark verification API. Newsrooms, election authorities, and law-enforcement units will be able
to upload a suspicious clip and immediately check whether the label is genuine. The beta is expected
before the 2026 state election calendar. Officials said exemptions for satire, archival footage, and
art projects will be finalized after a 30-day consultation, but political advertising and financial
advice will remain within mandatory labeling zones.

## What's Next

The ministry is working with startups at IIIT-Hyderabad to design tamper-resistant watermarks
backed by distributed ledgers. Quarterly compliance reports are now compulsory, and repeat offenders
can face temporary blocking orders. For creators, the guidance is straightforward: document which
model, prompt, and editing tools were used, embed an origin label before uploading, and retain logs
in case a takedown query arrives.

With these changes, India joins the EU and Singapore in drafting some of the most prescriptive
regulations on synthetic media, signaling that 2026 will be a year of zero tolerance for unlabeled
AI content.
